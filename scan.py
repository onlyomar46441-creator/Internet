#!/usr/bin/env python3
import socket
import concurrent.futures
import csv
from datetime import datetime
import requests
from bs4 import BeautifulSoup
import argparse
import warnings
from urllib3.exceptions import InsecureRequestWarning

# ØªØ¬Ø§Ù‡Ù„ ØªØ­Ø°ÙŠØ±Ø§Øª SSL Ù„Ø£ØºØ±Ø§Ø¶ Ø§Ù„Ù…Ø³Ø­ Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠ
warnings.filterwarnings("ignore", category=InsecureRequestWarning)

def check_web_server(ip, port, timeout=1):
    """ÙØ­Øµ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ù†ÙØ° Ù…ÙØªÙˆØ­Ø§Ù‹"""
    try:
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.settimeout(timeout)
        result = sock.connect_ex((ip, port))
        sock.close()
        return result == 0
    except:
        return False

def get_page_title(ip, port):
    """Ø¬Ù„Ø¨ Ø¹Ù†ÙˆØ§Ù† Ø§Ù„ØµÙØ­Ø© Ù…Ø¹ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©"""
    try:
        protocol = "https" if port == 443 else "http"
        url = f"{protocol}://{ip}:{port}"

        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø·Ù„Ø¨
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }

        response = requests.get(
            url,
            timeout=3,
            verify=False,
            headers=headers,
            allow_redirects=True
        )

        soup = BeautifulSoup(response.text, 'html.parser')

        # Ø¬Ù„Ø¨ Ø§Ù„Ø¹Ù†ÙˆØ§Ù†
        if soup.title and soup.title.string:
            title = soup.title.string.strip()[:100]  # Ù‚Øµ Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø·ÙˆÙŠÙ„
        else:
            title = "No Title"

        # Ø¬Ù„Ø¨ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©
        server_type = response.headers.get('Server', 'Unknown')
        content_type = response.headers.get('Content-Type', 'Unknown').split(';')[0]

        return title, server_type, content_type, response.status_code

    except requests.exceptions.SSLError:
        return "SSL Error", "Unknown", "Unknown", 0
    except requests.exceptions.Timeout:
        return "Timeout", "Unknown", "Unknown", 0
    except requests.exceptions.ConnectionError:
        return "Connection Error", "Unknown", "Unknown", 0
    except Exception as e:
        return f"Error: {str(e)[:50]}", "Unknown", "Unknown", 0

def scan_ip_port(args):
    """Ø¯Ø§Ù„Ø© Ù„Ù„ÙØ­Øµ ØªØ³ØªØ®Ø¯Ù… ÙÙŠ Threading"""
    ip, port, timeout = args

    if check_web_server(ip, port, timeout):
        title, server, content_type, status = get_page_title(ip, port)
        return ip, port, title, server, content_type, status, datetime.now().strftime("%H:%M:%S")

    return None

def main():
    # Ø¥Ø¹Ø¯Ø§Ø¯ CLI Arguments
    parser = argparse.ArgumentParser(description='Ù…Ø³Ø­ Ø®ÙˆØ§Ø¯Ù… Ø§Ù„ÙˆÙŠØ¨ Ø¹Ù„Ù‰ Ø§Ù„Ø´Ø¨ÙƒØ© Ø§Ù„Ù…Ø­Ù„ÙŠØ©')
    parser.add_argument('--network', default='192.168.1', help='Ù†Ø·Ø§Ù‚ Ø§Ù„Ø´Ø¨ÙƒØ© (default: 192.168.1)')
    parser.add_argument('--ports', default='80,443,8080,8000,3000', help='Ø§Ù„Ù…Ù†Ø§ÙØ° Ù„Ù„ÙØ­Øµ (comma-separated)')
    parser.add_argument('--threads', type=int, default=50, help='Ø¹Ø¯Ø¯ Ø§Ù„Ø®ÙŠÙˆØ· Ø§Ù„Ù…ØªÙˆØ§Ø²ÙŠØ© (default: 50)')
    parser.add_argument('--timeout', type=float, default=1, help='ÙˆÙ‚Øª Ø§Ù†ØªØ¸Ø§Ø± Ø§Ù„ÙØ­Øµ (default: 1)')
    parser.add_argument('--output', default='scan_results', help='Ø§Ø³Ù… Ù…Ù„Ù Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª (Ø¨Ø¯ÙˆÙ† Ø§Ù…ØªØ¯Ø§Ø¯)')

    args = parser.parse_args()

    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…Ù†Ø§ÙØ° Ø¥Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø©
    ports = [int(p) for p in args.ports.split(',')]

    # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ù„ÙØ§Øª
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    csv_file = f"{args.output}_{timestamp}.csv"
    txt_file = f"{args.output}_{timestamp}.txt"

    print(f"ğŸš€ Ø¨Ø¯Ø¡ ÙØ­Øµ Ø§Ù„Ø´Ø¨ÙƒØ© {args.network}.0/24")
    print(f"ğŸ” Ø§Ù„Ù…Ù†Ø§ÙØ°: {ports}")
    print(f"âš¡ Ø§Ù„Ø®ÙŠÙˆØ·: {args.threads}")
    print(f"â±ï¸  Ø§Ù„Ù…Ù‡Ù„Ø©: {args.timeout} Ø«Ø§Ù†ÙŠØ©")
    print("=" * 50)

    # Ø¥Ø¹Ø¯Ø§Ø¯ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ù‡Ø§Ù…
    tasks = []
    for i in range(1, 255):
        ip = f"{args.network}.{i}"
        for port in ports:
            tasks.append((ip, port, args.timeout))

    # ØªØ´ØºÙŠÙ„ Ø§Ù„ÙØ­Øµ Ø§Ù„Ù…ØªÙˆØ§Ø²ÙŠ
    found_servers = 0
    with open(csv_file, 'w', newline='', encoding='utf-8') as csv_f:
        csv_writer = csv.writer(csv_f)
        csv_writer.writerow(['IP', 'Port', 'Title', 'Server', 'Content-Type', 'Status', 'Time'])

        with open(txt_file, 'w', encoding='utf-8') as txt_f:
            txt_f.write(f"Ù†ØªØ§Ø¦Ø¬ ÙØ­Øµ Ø§Ù„Ø´Ø¨ÙƒØ© - {datetime.now()}\n")
            txt_f.write(f"Ø§Ù„Ø´Ø¨ÙƒØ©: {args.network}.0/24\n")
            txt_f.write(f"Ø§Ù„Ù…Ù†Ø§ÙØ°: {ports}\n")
            txt_f.write("=" * 60 + "\n\n")

            with concurrent.futures.ThreadPoolExecutor(max_workers=args.threads) as executor:
                future_to_task = {executor.submit(scan_ip_port, task): task for task in tasks}

                for future in concurrent.futures.as_completed(future_to_task):
                    result = future.result()
                    if result:
                        ip, port, title, server, content_type, status, scan_time = result

                        # Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ù†ØªÙŠØ¬Ø©
                        print(f"âœ… {ip}:{port} | {title} | Server: {server}")

                        # Ø­ÙØ¸ ÙÙŠ CSV
                        csv_writer.writerow([ip, port, title, server, content_type, status, scan_time])

                        # Ø­ÙØ¸ ÙÙŠ TXT
                        txt_f.write(f"ğŸ“ {ip}:{port}\n")
                        txt_f.write(f"   Ø§Ù„Ø¹Ù†ÙˆØ§Ù†: {title}\n")
                        txt_f.write(f"   Ø§Ù„Ø³ÙŠØ±ÙØ±: {server}\n")
                        txt_f.write(f"   Ù†ÙˆØ¹ Ø§Ù„Ù…Ø­ØªÙˆÙ‰: {content_type}\n")
                        txt_f.write(f"   Ø§Ù„Ø­Ø§Ù„Ø©: {status}\n")
                        txt_f.write(f"   ÙˆÙ‚Øª Ø§Ù„Ø§ÙƒØªØ´Ø§Ù: {scan_time}\n")
                        txt_f.write("-" * 40 + "\n")

                        found_servers += 1

    # Ø¥Ø¶Ø§ÙØ© Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª sqlmap
    with open(txt_file, 'a', encoding='utf-8') as txt_f:
        txt_f.write("\nğŸ”§ Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ù„Ù„ÙØ­Øµ Ø§Ù„Ø£Ø¹Ù…Ù‚ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… sqlmap:\n")
        txt_f.write("=" * 60 + "\n")

        # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù…Ù† CSV
        with open(csv_file, 'r', encoding='utf-8') as csv_f:
            reader = csv.DictReader(csv_f)
            for row in reader:
                protocol = "https" if row['Port'] == '443' else "http"
                url = f"{protocol}://{row['IP']}:{row['Port']}"
                txt_f.write(f"# sqlmap -u \"{url}/\" --batch --crawl=2 --level=2\n")

    print("\n" + "=" * 50)
    print(f"âœ… ØªÙ… Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„ÙØ­Øµ!")
    print(f"ğŸ“Š ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {found_servers} Ø®Ø§Ø¯Ù… ÙˆÙŠØ¨")
    print(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ:")
    print(f"   â€¢ {csv_file} (ØªÙ†Ø³ÙŠÙ‚ CSV)")
    print(f"   â€¢ {txt_file} (ØªÙ‚Ø±ÙŠØ± ØªÙØµÙŠÙ„ÙŠ)")

    if found_servers > 0:
        print("\nğŸ”— Ù„Ø¨Ø¯Ø¡ ÙØ­Øµ sqlmapØŒ Ø§Ø³ØªØ®Ø¯Ù…:")
        print(f"   cat {txt_file} | grep 'sqlmap' | head -5")

if __name__ == "__main__":
    main()